{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "skin_lesion_master.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alehb80/skin-lesion-classification/blob/master/skin_lesion_master.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jzKOqjwYggPF",
        "colab_type": "text"
      },
      "source": [
        "# SKIN LESION CLASSIFICATION"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FEeoxDu6WC4P",
        "colab_type": "text"
      },
      "source": [
        "## 1. Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vjwgAyAIgjyX",
        "colab_type": "text"
      },
      "source": [
        "### Import API Kaggle"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dkn4HhXGL3Hq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -q kaggle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TjzezNk9i9HE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir  ~/.kaggle\n",
        "!touch ~/.kaggle/kaggle-5.json\n",
        "\n",
        "api_token = {\"username\":\"gianlucavisentin\",\"key\":\"c609dca13d58751e6fc9d489a0dddb2d\"}\n",
        "\n",
        "import json\n",
        "\n",
        "with open('/root/.kaggle/kaggle.json', 'w') as file:\n",
        "    json.dump(api_token, file)\n",
        "\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I1dFi2cPnusn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install --upgrade --force-reinstall --no-deps kaggle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZY3jGd_xg06z",
        "colab_type": "text"
      },
      "source": [
        "### Search the dataset on Kaggle"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aq6V5lAWjnPz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!kaggle datasets list -s skin"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0j2lOxFbg6aR",
        "colab_type": "text"
      },
      "source": [
        "### Download the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R-KS3fzGnhCo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Copy the dataset locally\n",
        "!kaggle datasets download --force -d kmader/skin-cancer-mnist-ham10000"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WVq_kS7joDHL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip skin-cancer-mnist-ham10000.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yJCzJP5NhXxy",
        "colab_type": "text"
      },
      "source": [
        "### Import all libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hXFiUTNiWbmf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3oV7O2ciGSb4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import os\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "from glob import glob\n",
        "import seaborn as sns\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "import keras\n",
        "from keras.utils.np_utils import to_categorical\n",
        "# from keras.models import Sequential\n",
        "# from keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPool2D\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.optimizers import Adam\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.callbacks import ReduceLROnPlateau"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MnZwumqIWcNS",
        "colab_type": "text"
      },
      "source": [
        "## 2. Data Analysis And Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X5g447OzWwOb",
        "colab_type": "text"
      },
      "source": [
        "### Build Dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w1Hi7RwMFk1K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# merge the images in jpg format from both the folders\n",
        "base_skin_dir = \"./\"\n",
        "imageid_path_dict = {os.path.splitext(os.path.basename(x))[0]: x\n",
        "                     for x in glob(os.path.join(base_skin_dir, '*', '*.jpg'))}\n",
        "\n",
        "lesion_type_dict = {\n",
        "    'nv': 'Melanocytic nevi',\n",
        "    'mel': 'Melanoma',\n",
        "    'bkl': 'Benign keratosis-like lesions ',\n",
        "    'bcc': 'Basal cell carcinoma',\n",
        "    'akiec': 'Actinic keratoses',\n",
        "    'vasc': 'Vascular lesions',\n",
        "    'df': 'Dermatofibroma'\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dY-fYSLsHb7v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "tile_df = pd.read_csv(os.path.join(base_skin_dir, 'HAM10000_metadata.csv'))\n",
        "\n",
        "# Creating New Columns for better readability\n",
        "tile_df['path'] = tile_df['image_id'].map(imageid_path_dict.get)\n",
        "tile_df['cell_type'] = tile_df['dx'].map(lesion_type_dict.get) \n",
        "tile_df['cell_type_idx'] = pd.Categorical(tile_df['cell_type']).codes\n",
        "tile_df.sample(6)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fgt7f0jMLcC5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tile_df[\"age\"].hist()\n",
        "plt.title(\"Distribution of Age\", fontdict={\"fontsize\" : 20});"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GLN4zFy0LuKb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tile_df[\"sex\"].hist()\n",
        "plt.title(\"Male or Female\", fontdict={\"fontsize\" : 20});"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nzP_VOCtMF2x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tile_df[\"localization\"].hist()\n",
        "plt.title(\"Where are skin lesions?\", fontdict={\"fontsize\" : 20});\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kgte8oRDNqSc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tile_df[\"cell_type\"].hist()\n",
        "plt.title(\"Where are skin lesions?\", fontdict={\"fontsize\" : 20});"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xHrCZnMxhran",
        "colab_type": "text"
      },
      "source": [
        "### Cleaning Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZaUHsvVGiD2r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# show if there is a null data\n",
        "tile_df.isnull().sum()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kazkZQj0i7B4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# calculate te mean value of the \"age\" feature\n",
        "print(tile_df['age'].mean())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TJyXiipPiowl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# fill the null values by their mean\n",
        "tile_df['age'].fillna((tile_df['age'].mean()), inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8t_Wj6uLitao",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# show if there is a null data\n",
        "tile_df.isnull().sum()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1qBoLmnyXvo-",
        "colab_type": "text"
      },
      "source": [
        "### View Image Samples"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U-pDJMBJjWc6",
        "colab_type": "text"
      },
      "source": [
        "### Loading and resize images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kj7f8DWUmwF7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# show some image samples\n",
        "n_samples = 3\n",
        "fig, m_axs = plt.subplots(7, n_samples, figsize = (4*n_samples, 3*7))\n",
        "for n_axs, (type_name, type_rows) in zip(m_axs, \n",
        "                                         tile_df.sort_values(['cell_type']).groupby('cell_type')):\n",
        "    n_axs[0].set_title(type_name)\n",
        "    for c_ax, (_, c_row) in zip(n_axs, type_rows.sample(n_samples, random_state=1234).iterrows()):\n",
        "        c_ax.imshow(c_row['image'])\n",
        "        c_ax.axis('off')\n",
        "fig.savefig('category_samples.png', dpi=300)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q6AnS3J4jdYO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# resize the images to 100 * 75 which tensorflow can handle\n",
        "tile_df['image'] = tile_df['path'].map(lambda x: np.asarray(Image.open(x).resize((100,75))))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7PDD_xSJn4qn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# checking the image size distribution\n",
        "tile_df['image'].map(lambda x: x.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vPeYFcFboOyv",
        "colab_type": "text"
      },
      "source": [
        "## 3. Build The Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8BLI3uIRoR_C",
        "colab_type": "text"
      },
      "source": [
        "### Split data into train and test with 80:20 ratio"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aqFhA1zjoY4p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "features=tile_df.drop(columns=['cell_type_idx'],axis=1)\n",
        "target=tile_df['cell_type_idx']\n",
        "\n",
        "# 'train_test_split' splits arrays or matrices into random train and test subsets\n",
        "x_train_o, x_test_o, y_train_o, y_test_o = train_test_split(features, target, test_size=0.20,random_state=1234)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tBop4IFdrAyD",
        "colab_type": "text"
      },
      "source": [
        "### Normalization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qo_6cVL6rKzE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# subtract their mean values from it and then dividing by their standard deviation\n",
        "x_train = np.asarray(x_train_o['image'].tolist())\n",
        "x_test = np.asarray(x_test_o['image'].tolist())\n",
        "\n",
        "x_train_mean = np.mean(x_train)\n",
        "x_train_std = np.std(x_train)\n",
        "\n",
        "x_test_mean = np.mean(x_test)\n",
        "x_test_std = np.std(x_test)\n",
        "\n",
        "x_train = (x_train - x_train_mean)/x_train_std\n",
        "x_test = (x_test - x_test_mean)/x_test_std"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3mReFJznrQJx",
        "colab_type": "text"
      },
      "source": [
        "### Label Encoding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bspJmqzvrWnA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# labels are 7 different classes of cell types from 0 to 6. We need to encode these lables to one hot vectors\n",
        "y_train = to_categorical(y_train_o, num_classes = 7)\n",
        "y_test = to_categorical(y_test_o, num_classes = 7)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eQw4Lg3prceg",
        "colab_type": "text"
      },
      "source": [
        "### Training and Validation Split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fJviJtdKrgnj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# validate:train >> 10:90 %\n",
        "x_train, x_validate, y_train, y_validate = train_test_split(x_train, y_train, test_size = 0.2, random_state = 2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cLPozoZnrj_V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = x_train.reshape(x_train.shape[0], *(75, 100, 3))\n",
        "x_test = x_test.reshape(x_test.shape[0], *(75, 100, 3))\n",
        "x_validate = x_validate.reshape(x_validate.shape[0], *(75, 100, 3))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dLVt51ceroHL",
        "colab_type": "text"
      },
      "source": [
        "## 4. Model Building"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b1oT6BcPa3D3",
        "colab_type": "text"
      },
      "source": [
        "### Define the deep convolutional network architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QtmyTqFYruok",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#input_shape = (75, 100, 3)\n",
        "#num_classes = 7\n",
        "#model = Sequential([\n",
        " #   Conv2D(32, 3, padding='same', activation='relu', input_shape=input_shape),\n",
        "  #  Conv2D(32, 3, padding='same', activation='relu'),\n",
        "   # MaxPooling2D(),\n",
        "    #Dropout(0.25),\n",
        "\n",
        "    #Conv2D(64, 3, padding='same', activation='relu', input_shape=input_shape),\n",
        "    #Conv2D(64, 3, padding='same', activation='relu'),\n",
        "    #MaxPooling2D(),\n",
        "    #Dropout(0.4),\n",
        "    \n",
        "    #Conv2D(128, 3, padding='same', activation='relu'),\n",
        "    #MaxPooling2D(),\n",
        "    #Dropout(0.5),\n",
        "    \n",
        "   # Flatten(),\n",
        "   # Dense(128, activation='relu'),\n",
        "    #Dropout(0.5),\n",
        "    \n",
        "    #Dense(7, activation='softmax')\n",
        "#])\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "\n",
        "# Our input feature map is 75x100x3: 75x100 for the image pixels, and 3 for\n",
        "# the three color channels: R, G, and B\n",
        "img_input = layers.Input(shape=(75, 100, 3))\n",
        "\n",
        "# First convolution extracts 16 filters that are 3x3\n",
        "# Convolution is followed by max-pooling layer with a 2x2 window\n",
        "x = layers.Conv2D(16, 3, activation='relu', padding='same')(img_input)\n",
        "x = layers.MaxPooling2D(2)(x)\n",
        "\n",
        "# Second convolution extracts 32 filters that are 3x3\n",
        "# Convolution is followed by max-pooling layer with a 2x2 window\n",
        "x = layers.Conv2D(32, 3, activation='relu', padding='same')(x)\n",
        "x = layers.MaxPooling2D(2)(x)\n",
        "\n",
        "# Third convolution extracts 64 filters that are 3x3\n",
        "# Convolution is followed by max-pooling layer with a 2x2 window\n",
        "x = layers.Convolution2D(64, 3, activation='relu', padding='same')(x)\n",
        "x = layers.MaxPooling2D(2)(x)\n",
        "\n",
        "# Flatten feature map to a 1-dim tensor\n",
        "x = layers.Flatten()(x)\n",
        "\n",
        "# Create a fully connected layer with ReLU activation and 512 hidden units\n",
        "x = layers.Dense(512, activation='relu')(x)\n",
        "\n",
        "# Add a dropout rate of 0.5\n",
        "x = layers.Dropout(0.5)(x)\n",
        "\n",
        "# Create output layer with a single node and softmax activation\n",
        "output = layers.Dense(7, activation='softmax')(x)\n",
        "\n",
        "# Configure and compile the model\n",
        "model = Model(img_input, output)\n",
        "\n",
        "optimizer = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Pbijr2cr0kE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#model.compile(optimizer='adam',\n",
        "             # loss='binary_crossentropy',\n",
        "             #metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HI1umXeW8bOR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "#model.compile(loss='binary_crossentropy', optimizer='adam', metrics=[accuracy])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_1n-q5Hmr3EX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "def get_call_back():\n",
        "  reduce_lr = tf.keras.callbacks.ReduceLROnPlateau()\n",
        "  reduce_lr = ReduceLROnPlateau(monitor='val_accuracy', \n",
        "                                            patience=3, \n",
        "                                            verbose=1, \n",
        "                                          factor=0.5, \n",
        "                                           min_lr=0.00001)\n",
        "  return[reduce_lr]\n",
        "\n",
        "#reduce_lr = ReduceLROnPlateau(monitor='val_loss',\n",
        "                                 #factor=0.2,\n",
        "                                #patience=5,\n",
        "                                 #  min_lr=0.001)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KPHOjkqmr53s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1zN8ANuYbMNN",
        "colab_type": "text"
      },
      "source": [
        "### Avoid the overfitting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KSejfxP_sL5g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# avoiding the overfitting\n",
        "datagen = ImageDataGenerator(\n",
        "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
        "        samplewise_center=False,  # set each sample mean to 0\n",
        "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
        "        samplewise_std_normalization=False,  # divide each input by its std\n",
        "        zca_whitening=False,  # apply ZCA whitening\n",
        "        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "        zoom_range = 0.1, # Randomly zoom image \n",
        "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
        "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
        "        horizontal_flip=False,  # randomly flip images\n",
        "        vertical_flip=False\n",
        "        )  # randomly flip images\n",
        "datagen.fit(x_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EMfWAWs5bVr0",
        "colab_type": "text"
      },
      "source": [
        "## 5. Train Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zBCysEOhsQAt",
        "colab_type": "text"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D84peUa7sUiD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#epochs = 50 \n",
        "epochs = 30 \n",
        "batch_size = 160\n",
        "history = model.fit(\n",
        "    datagen.flow(x_train,y_train, batch_size=batch_size),\n",
        "    steps_per_epoch=x_train.shape[0] // batch_size,\n",
        "    epochs=epochs,\n",
        "    validation_data=(x_validate,y_validate),\n",
        "    validation_steps=x_validate.shape[0] // batch_size\n",
        "    ,callbacks=get_call_back()\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TdL5SPADv9Ff",
        "colab_type": "text"
      },
      "source": [
        "## 6. Evaluate Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GG6qpHgEbxUz",
        "colab_type": "text"
      },
      "source": [
        "### Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hGvXmaGpv_0V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss, accuracy = model.evaluate(x_test, y_test, verbose=1)\n",
        "loss_v, accuracy_v = model.evaluate(x_validate, y_validate, verbose=1)\n",
        "print(\"Validation: accuracy = %f  ;  loss_v = %f\" % (accuracy_v, loss_v))\n",
        "print(\"Test: accuracy = %f  ;  loss = %f\" % (accuracy, loss))\n",
        "model.save(\"model.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OTjktfaRblKP",
        "colab_type": "text"
      },
      "source": [
        "### Visualize Learning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SqQkXYq_wVSG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#1. Function to plot model's validation loss and validation accuracy\n",
        "def plot_model_history(model_history):\n",
        "    fig, axs = plt.subplots(1,2,figsize=(15,5))\n",
        "    # summarize history for accuracy\n",
        "    axs[0].plot(range(1,len(model_history.history['accuracy'])+1),model_history.history['accuracy'])\n",
        "    axs[0].plot(range(1,len(model_history.history['val_accuracy'])+1),model_history.history['val_accuracy'])\n",
        "    axs[0].set_title('Model Accuracy')\n",
        "    axs[0].set_ylabel('Accuracy')\n",
        "    axs[0].set_xlabel('Epoch')\n",
        "    axs[0].set_xticks(np.arange(1,len(model_history.history['accuracy'])+1),len(model_history.history['accuracy'])/10)\n",
        "    axs[0].legend(['train', 'val'], loc='best')\n",
        "    # summarize history for loss\n",
        "    axs[1].plot(range(1,len(model_history.history['loss'])+1),model_history.history['loss'])\n",
        "    axs[1].plot(range(1,len(model_history.history['val_loss'])+1),model_history.history['val_loss'])\n",
        "    axs[1].set_title('Model Loss')\n",
        "    axs[1].set_ylabel('Loss')\n",
        "    axs[1].set_xlabel('Epoch')\n",
        "    axs[1].set_xticks(np.arange(1,len(model_history.history['loss'])+1),len(model_history.history['loss'])/10)\n",
        "    axs[1].legend(['train', 'val'], loc='best')\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WWR1ppGUwX1b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_model_history(history)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}